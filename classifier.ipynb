{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dfbe3e48319960c2d42c296b30c22840b3359d6c"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this notebook, I will apply classification algorithms with scikit-learn library. Firstly, EDA(Exploratory Data Analysis) will be applied to dataset. Then, different algorithms will classify dataset.\n",
    "\n",
    "[0. EDA(Exploratory Data Analysis)](#1)\n",
    "\n",
    "[1. K-Nearest Neighbor Algorithm](#2)\n",
    "\n",
    "[2. Support Vector Machine(SVM)](#3)\n",
    "\n",
    "[3. Naive-Bayes Classification](#4)\n",
    "\n",
    "[4. Decision Tree Classification](#5)\n",
    "\n",
    "[5. Random Forest Classification](#6)\n",
    "\n",
    "[6.  Conclusion](#7)\n",
    "\n",
    "[7.  References](#8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "310140792cd4e1daf19873d7739990517cdb72e9"
   },
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "## EDA (Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../input/breastCancer.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a8af59c3c1d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../input/breastCancer.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1015\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1708\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'../input/breastCancer.csv' does not exist"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('breastCancer.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "48c5e6150e9df0e2a005f7ac4dba524d9101309b"
   },
   "outputs": [],
   "source": [
    "# Clear the noisy attributes\n",
    "data.drop([\"id\",\"Unnamed: 32\"],axis=1,inplace=True)\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "049f9cb3b0d7ce0bd4c27158a90f3fe6beacaf84"
   },
   "outputs": [],
   "source": [
    "M = data[data.diagnosis=='M']\n",
    "B = data[data.diagnosis=='B']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "89c1c1ff83dce83689da9742d7660bd4049b130e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(M.radius_mean,M.texture_mean,color='red',label='Malignant',alpha=0.3)\n",
    "plt.scatter(B.radius_mean,B.texture_mean,color='green',label='Benign',alpha=0.3)\n",
    "plt.xlabel('Malignant')\n",
    "plt.ylabel('Benign')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "47f2f1d6f7450be3240ef0aaa673a0403f44f2d7"
   },
   "outputs": [],
   "source": [
    "# Change M and B values to 0 and 1\n",
    "# Prepare x and y values for KNN algorithm\n",
    "data.diagnosis= [1 if each==\"M\" else 0 for each in data.diagnosis]\n",
    "y=data.diagnosis.values\n",
    "x_data = data.drop([\"diagnosis\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "145c9529c3eceb5b8a1871af8dedd314b0aafbbf"
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "x = (x_data-np.min(x_data))/(np.max(x_data)-np.min(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbb694de40513d75fdd9d1d600e2e5f08e19fda3"
   },
   "outputs": [],
   "source": [
    "# Train-Test Split for Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cdcc281f2649872abfd76eda23c50c54978389f7"
   },
   "source": [
    "<a id=\"2\"></a><br>\n",
    "## KNN(K-Nearest Neighbor) Classification\n",
    "\n",
    "![KNN](https://www.kdnuggets.com/wp-content/uploads/knn2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "77d9fcedeca1df96bb927e91cee05e9e4a09e99e"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3) #k=3\n",
    "knn.fit(x_train,y_train)\n",
    "prediction = knn.predict(x_test)\n",
    "print(\"{} nn score: {}\".format(3,knn.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c04cba9b9905d76e8578e3606d8472979d2bbc9a"
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning\n",
    "score_list = []\n",
    "for each in range(1,15):\n",
    "    knn2 = KNeighborsClassifier(n_neighbors = each)\n",
    "    knn2.fit(x_train,y_train)\n",
    "    score_list.append(knn2.score(x_test,y_test))\n",
    "    \n",
    "plt.plot(range(1,15),score_list)\n",
    "plt.xlabel(\"k values\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a2bb912547674387883d51c22bf600d568b16b4e"
   },
   "source": [
    "<a id=\"3\"></a><br>\n",
    "## SUPPORT VECTOR MACHINE(SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5dbfb820d688ed9f222d92a6fd163a7c4dca475d"
   },
   "source": [
    "![](http://www.saedsayad.com/images/SVM_2.png)\n",
    "\n",
    "I will not explain how SVM algorithm works. However, I found a great page for understand SVM algorithm. \n",
    "So you can look detailed information about SVM in there : [Support Vector Machine](http://www.saedsayad.com/support_vector_machine.htm)\n",
    "\n",
    "**Note : Our x,y, train-test split(x_data,y_data) values are prepared from the previous algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53bf665db78a6858070694fb40506e4d67f5c9be"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=1) # Return the same value every time\n",
    "svm.fit(x_train,y_train)\n",
    "\n",
    "# test\n",
    "print(\"primy accuracy of SVM algorithm : \",svm.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "745ad114c9a5ba42100ce9ef0b8a152644c327ea"
   },
   "source": [
    "<a id=\"4\"></a><br>\n",
    "## Naive-Bayes Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e542be892ffee204000df058d5d1476170abeda9"
   },
   "source": [
    "Here is the another probabilstic approach for machine learning. You can look the Bayes Theorem from this page.\n",
    "![Naive-Bayes](http://www.saedsayad.com/images/Bayes_rule.png)\n",
    "[Naive-Bayes Classification](http://www.saedsayad.com/naive_bayesian.htm)\n",
    "\n",
    "**Note : Our x,y, train-test split(x_data,y_data) values prepared from the previous algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f1d2b97db7951c88b374b5431295160bd1fa6328"
   },
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "\n",
    "#test\n",
    "print(\"Accuracy of Naive-Bayes Algorithm\",nb.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ba253736d5db8b4fc58a533c3dc873a48954cca2"
   },
   "source": [
    "<a id=\"5\"></a><br>\n",
    "## Decision Tree Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "963cafe91c7d63ec50cae5e446a99b6e717c7c55"
   },
   "source": [
    "<img src=\"https://tr.akinator.com/bundles/elokencesite/images/akinator.png?v95\" alt=\"drawing\" height=\"300\" width=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8077e25e6a52adc2aab6edaac9a365b8c2202511"
   },
   "source": [
    "Have you ever played Akinator Game? It is a great example of decision trees. If you haven't yet, let me explain. The goal of the game is predict a famous character, based of bunch of questions which asked to us. After the each answer, questions are getting more relevant to famous person which is in our mind. Finally, akinator shows his predict. Mostly, he justifies about the prediction.\n",
    "\n",
    "Decision tree algorithm works behind the akinator. There are splits which decides to person to based on the answers. For example if we are looking for a person which is blonde then it redirects the future predictions to \"blonde\" people. \"Blonde\" input is given by the user as an answer for a question.\n",
    "\n",
    "If you want to play the game, the link is below.\n",
    "\n",
    "https://en.akinator.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b603b6a3268d661e4144e99723aec87f010166e9"
   },
   "source": [
    "![](https://annalyzin.files.wordpress.com/2016/07/decision-trees-titanic-tutorial.png?w=616&h=342)\n",
    "Source : https://annalyzin.files.wordpress.com/2016/07/decision-trees-titanic-tutorial.png?w=616&h=342"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8fc543d19fe5c3d564e1e4f99a5c3ba8c96f2c34"
   },
   "source": [
    "You can see the splits. It can be more than two splits. In this example, we have a binary tree. The bottom nodes known as \"leaf\". These are our predictions. The top node is \"root\" node. In a nutshell, let's start the code.\n",
    "\n",
    "* EDA and Normalization have already done in the previous sections. \n",
    "* Train-Test split is obtained in the previous sections. But I want to change percentage of test split to 15%\n",
    "\n",
    "Let's start at the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "234092e6f39dc083e518e941ceb403a447649b8b"
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.15,random_state=42)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)\n",
    "# Accuracy\n",
    "print(\"Accuracy of Decision Tree Algorithm\",dt.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d3068a791936c8c45e5213ffc7487489871d8abf"
   },
   "source": [
    "<a id=\"6\"></a><br>\n",
    "# Random Forest Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3d3e56fe87e438b4656d4ee8ac6f0a9c1ed3f504"
   },
   "source": [
    "* The random forest is a \"ensemble learning\" algorithm. So, it includes more than one classification algorithm. The \"forest\" name comes from to our trees. In a nutshell, random forest classification is includes 'n' trees in itself. \n",
    "\n",
    "* While we make predictions, different results(classes) can occur. In order to reduce our prediction to a singe class, we will use \"Majority Voting\". It is simple, which count of class is bigger than to other it will be final result.\n",
    "\n",
    "* Estimator = Number of trees for our random forest classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "883f12ca11dc0d289c49d0a813799f2d80632575"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100,random_state=1) # Number of tree = 100\n",
    "rf.fit(x_train,y_train)\n",
    "print(\"Accuracy of Random Forest Algorithm\",rf.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "afd66870fce491cf874305f0d7814206e8f53809"
   },
   "source": [
    "We can see that, accuracy is increased. However, we can't be sure about the number of estimators. In order to choose best number of estimators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f30690248d1e38d2eb8a9d8970f29404b6e2e45f"
   },
   "outputs": [],
   "source": [
    "accuracy_list=[]\n",
    "for i in range(1,11,1):\n",
    "    rf = RandomForestClassifier(n_estimators=i,random_state=1) # Number of tree = 100\n",
    "    rf.fit(x_train,y_train)\n",
    "    accuracy_list.append(rf.score(x_test,y_test))\n",
    "    #print(\"Accuracy of Random Forest Algorithm for {} trees: {}\".format(i,rf.score(x_test,y_test)))\n",
    "plt.plot(range(1,11),accuracy_list)\n",
    "plt.xlabel(\"Number of estimators\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7d422507f0f2a286d1d62fc7ce107b8732b06db6"
   },
   "source": [
    "We can see that, optimum number of estimators is 4. There is no need to 100 trees. Hence, we can obtain same result with less trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "82adb89dd98ef252cc99e48d0411590169889671"
   },
   "source": [
    "<a id=\"7\"></a><br>\n",
    "## Conclusion\n",
    "\n",
    "* You have seen which algorithm is better. Of course **none of them**. All algorithms have trade-offs. You should pick your algorithm for your scenario. \n",
    "\n",
    "* Do not forget tuning **hyperparameters** for the better results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cf2431a8cc90a9db55dba6dba786b7104c3a50e0"
   },
   "source": [
    "<a id=\"8\"></a><br>\n",
    "## References\n",
    "\n",
    "https://www.kaggle.com/kanncaa1/machine-learning-tutorial-for-beginners\n",
    "\n",
    "http://www.saedsayad.com/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
